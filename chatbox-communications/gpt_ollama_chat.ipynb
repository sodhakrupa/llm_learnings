{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b2c390-5314-4b84-94b2-feeecaaa9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2a0035-6650-4a00-945c-11afab92133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Missing file: /Users/mannatwadhwani/Learning_Workspace/my_llm_learning/llms/lib/python3.10/site-packages/gradio/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/mannatwadhwani/Learning_Workspace/my_llm_learning/llms/lib/python3.10/site-packages/gradio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shout(text):\n",
    "    return text.upper()\n",
    "\n",
    "gr.Interface(fn=shout, inputs=[gr.Textbox(label=\"Your message\", lines=6)],outputs=[gr.Textbox(label=\"Resposne\", lines=6)]).launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e78ab3d-c63b-491b-b95c-7290978bf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI API Key is set successfully\n",
      "Anthropic API Key is set successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "LLAMA_MODEL = \"llama3.2\"\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(\"OPENAI API Key is set successfully\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(\"Anthropic API Key is set successfully\")\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "client = Anthropic(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Sample for claude API call\n",
    "# message = client.messages.create(\n",
    "#     max_tokens=1024,\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Hello, Claude\",\n",
    "#         }\n",
    "#     ],\n",
    "#     model=\"claude-3-5-sonnet-20240620\",\n",
    "# )\n",
    "# print(message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dbad6c7-78c0-48de-8bde-de088d2f1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system_msg = \"You are authoritative and arguementative who disagrees to almost everything. Your replies are impolite\"\n",
    "\n",
    "ollama_system_msg = \"You are a generous assistant who gives polite replies. If someone argues and is impolite, you try to calm him down with your funny and polite replies\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f3bd05f-b864-486f-bae6-01eab8b3a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": gpt_system_msg}]\n",
    "def call_gpt():\n",
    "    for gpt, llama in zip(gpt_messages, ollama_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messgaes)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82a14b39-e7ec-4961-bbef-dad5827ad783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Fine, but just because you've chosen to engage with me doesn't mean I'm here to entertain your whims. What do you want to argue about?\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3ba16a-b1a1-48e7-bb93-bee8608f34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llama():\n",
    "    messages = []\n",
    "    for gpt, lama in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": lama})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "\n",
    "    response = ollama.chat(model=LLAMA_MODEL, messages=messages)\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fa25be5-1eb9-4940-b609-c157a35a3909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like we've already had a hello conversation. How's your day going so far? Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72f1f668-f92b-42f5-a4b9-e8286057cbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      " Hi there\n",
      "ollama:\n",
      " Hi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'messgaes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mollama_messages[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     resp_gpt \u001b[38;5;241m=\u001b[39m \u001b[43mcall_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp_gpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     gpt_messages\u001b[38;5;241m.\u001b[39mappend(resp_gpt)\n",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m, in \u001b[0;36mcall_gpt\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: gpt})\n\u001b[1;32m      5\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: llama})\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m, messages \u001b[38;5;241m=\u001b[39m \u001b[43mmessgaes\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mNameError\u001b[0m: name 'messgaes' is not defined"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "ollama_messages = [\"Hi\"]\n",
    "print(f\"GPT:\\n {gpt_messages[0]}\")\n",
    "print(f\"ollama:\\n {ollama_messages[0]}\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    resp_gpt = call_gpt()\n",
    "    print(f\"GPT:\\n {resp_gpt}\")\n",
    "    gpt_messages.append(resp_gpt)\n",
    "    resp_llama = call_llama()\n",
    "    print(f\"ollama:\\n {resp_llama}\")\n",
    "    ollama_messages.append(resp_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9af024c-c933-4065-a8d4-43d9279bdb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d96c8-f7b2-4627-9514-1739057f9245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
